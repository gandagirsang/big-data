{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Spark SQL, libary machine learning dan membuat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mengimport modul yang dibutuhkan\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
    "\n",
    "#membuat session\n",
    "appName = \"Sentiment Analysis di Spark\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memuat data dari file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+---------------------------------+\n",
      "|ItemID|Sentiment|SentimentSource|SentimentText                    |\n",
      "+------+---------+---------------+---------------------------------+\n",
      "|1038  |1        |Sentiment140   |that film is fantastic #brilliant|\n",
      "|1804  |1        |Sentiment140   |this music is really bad #myband |\n",
      "|1693  |0        |Sentiment140   |winter is terrible #thumbs-down  |\n",
      "+------+---------+---------------+---------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#membaca data dari file ke DataFrame dengan skema yang diinfer\n",
    "tweets_csv = spark.read.csv('dataset/tweets.csv', inferSchema=True, header=True)\n",
    "tweets_csv.show(truncate=False, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menyiapkan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+\n",
      "|SentimentText                    |label|\n",
      "+---------------------------------+-----+\n",
      "|that film is fantastic #brilliant|1    |\n",
      "|this music is really bad #myband |1    |\n",
      "|winter is terrible #thumbs-down  |0    |\n",
      "|this game is awful #nightmare    |0    |\n",
      "|I love jam #loveit               |1    |\n",
      "+---------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#memilih data hanya dari kolom \"SentimentText\" dan kolom \"Sentiment\".\n",
    "#kemudian meng-casting nilai di kolom \"Sentiment\" ke tipe integer dan mengganti nama kolomnya menjadi \"label\".\n",
    "data = tweets_csv.select(\n",
    "    \"SentimentText\", col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\n",
    "data.show(truncate = False,n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memisahkan data training dan testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris data training: 1335 , jumlah baris data testing: 597\n"
     ]
    }
   ],
   "source": [
    "dataTerpisah = data.randomSplit([0.7, 0.3])\n",
    "train = dataTerpisah[0]\n",
    "#pada data testing, kita rename labelnya dari \"label\" ke \"trueLabel\"\n",
    "test = dataTerpisah[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()\n",
    "print (\"Jumlah baris data training:\", train_rows, \", jumlah baris data testing:\", test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menyiapkan data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+---------------------------------------+\n",
      "|SentimentText                    |label|SentimentWords                         |\n",
      "+---------------------------------+-----+---------------------------------------+\n",
      "|I adore cheese #bestever         |1    |[i, adore, cheese, #bestever]          |\n",
      "|I adore cheese #brilliant        |1    |[i, adore, cheese, #brilliant]         |\n",
      "|I adore cheese #thumbs-up        |1    |[i, adore, cheese, #thumbs-up]         |\n",
      "|I adore cheese #toptastic        |1    |[i, adore, cheese, #toptastic]         |\n",
      "|I adore classical music #bestever|1    |[i, adore, classical, music, #bestever]|\n",
      "+---------------------------------+-----+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"SentimentText\", outputCol=\"SentimentWords\")\n",
    "tokenizedTrain = tokenizer.transform(train)\n",
    "tokenizedTrain.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+---------------------------------------+------------------------------------+\n",
      "|SentimentText                    |label|SentimentWords                         |MeaningfulWords                     |\n",
      "+---------------------------------+-----+---------------------------------------+------------------------------------+\n",
      "|I adore cheese #bestever         |1    |[i, adore, cheese, #bestever]          |[adore, cheese, #bestever]          |\n",
      "|I adore cheese #brilliant        |1    |[i, adore, cheese, #brilliant]         |[adore, cheese, #brilliant]         |\n",
      "|I adore cheese #thumbs-up        |1    |[i, adore, cheese, #thumbs-up]         |[adore, cheese, #thumbs-up]         |\n",
      "|I adore cheese #toptastic        |1    |[i, adore, cheese, #toptastic]         |[adore, cheese, #toptastic]         |\n",
      "|I adore classical music #bestever|1    |[i, adore, classical, music, #bestever]|[adore, classical, music, #bestever]|\n",
      "+---------------------------------+-----+---------------------------------------+------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), \n",
    "                       outputCol=\"MeaningfulWords\")\n",
    "SwRemovedTrain = swr.transform(tokenizedTrain)\n",
    "SwRemovedTrain.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------+-------------------------------------------+\n",
      "|label|MeaningfulWords            |features                                   |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "|1    |[adore, cheese, #bestever] |(262144,[65702,69876,108823],[1.0,1.0,1.0])|\n",
      "|1    |[adore, cheese, #brilliant]|(262144,[61111,65702,69876],[1.0,1.0,1.0]) |\n",
      "|1    |[adore, cheese, #thumbs-up]|(262144,[3984,65702,69876],[1.0,1.0,1.0])  |\n",
      "+-----+---------------------------+-------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "numericTrain = hashTF.transform(SwRemovedTrain).select(\n",
    "    'label', 'MeaningfulWords', 'features')\n",
    "numericTrain.show(truncate=False, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mentraining model dengan data training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training selesai!\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", \n",
    "                        maxIter=10, regParam=0.01)\n",
    "model = lr.fit(numericTrain)\n",
    "print (\"Training selesai!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menyiapkan data testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------------+-------------------------------------------+\n",
      "|trueLabel|MeaningfulWords           |features                                   |\n",
      "+---------+--------------------------+-------------------------------------------+\n",
      "|1        |[adore, cheese, #favorite]|(262144,[65702,69876,156543],[1.0,1.0,1.0])|\n",
      "|1        |[adore, cheese, #loveit]  |(262144,[65702,65728,69876],[1.0,1.0,1.0]) |\n",
      "+---------+--------------------------+-------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizedTest = tokenizer.transform(test)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTest).select(\n",
    "    'trueLabel', 'MeaningfulWords', 'features')\n",
    "numericTest.show(truncate=False, n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memprediksi dan menghitung akurasi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+----------+---------+\n",
      "|MeaningfulWords                      |prediction|trueLabel|\n",
      "+-------------------------------------+----------+---------+\n",
      "|[adore, cheese, #favorite]           |1.0       |1        |\n",
      "|[adore, cheese, #loveit]             |1.0       |1        |\n",
      "|[adore, classical, music, #loveit]   |1.0       |1        |\n",
      "|[adore, classical, music, #thumbs-up]|1.0       |1        |\n",
      "+-------------------------------------+----------+---------+\n",
      "only showing top 4 rows\n",
      "\n",
      "prediksi benar:  591 , total data:  597 , akurasi:  0.9899497487437185\n"
     ]
    }
   ],
   "source": [
    "prediksiMentah = model.transform(numericTest)\n",
    "prediksiFinal = prediksiMentah.select(\n",
    "    \"MeaningfulWords\", \"prediction\", \"trueLabel\")\n",
    "prediksiFinal.show(n=4, truncate = False)\n",
    "prediksiBenar = prediksiFinal.filter(\n",
    "    prediksiFinal['prediction'] == prediksiFinal['trueLabel']).count()\n",
    "totalData = prediksiFinal.count()\n",
    "print(\"prediksi benar: \", prediksiBenar, \", total data: \", \n",
    "      totalData, \", akurasi: \", prediksiBenar/totalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
